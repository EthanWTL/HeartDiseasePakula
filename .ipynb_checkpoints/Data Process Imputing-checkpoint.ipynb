{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed05285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2c3ed",
   "metadata": {},
   "source": [
    "# Local data for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37651f",
   "metadata": {},
   "source": [
    "## Cleveland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e281b4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
      "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
      "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
      "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
      "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
      "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
      "\n",
      "     slope   ca thal  num  \n",
      "0      3.0  0.0  6.0    0  \n",
      "1      2.0  3.0  3.0    2  \n",
      "2      2.0  2.0  7.0    1  \n",
      "3      3.0  0.0  3.0    0  \n",
      "4      1.0  0.0  3.0    0  \n",
      "..     ...  ...  ...  ...  \n",
      "298    2.0  0.0  7.0    1  \n",
      "299    2.0  2.0  7.0    2  \n",
      "300    2.0  1.0  7.0    3  \n",
      "301    2.0  1.0  3.0    1  \n",
      "302    1.0    ?  3.0    0  \n",
      "\n",
      "[303 rows x 14 columns]\n",
      "Missing values: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_5616\\706876550.py:9: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_cleveland.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cleveland = 'data/processed.cleveland.data'\n",
    "\n",
    "df_cleveland = pd.read_csv(cleveland, header=None)\n",
    "\n",
    "columns_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "df_cleveland.columns = columns_names\n",
    "print(df_cleveland)\n",
    "\n",
    "df_cleveland.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_cleveland.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d7a145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "3       0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "298     1.0     0.0     0.0     0.0          1.0          0.0          0.0   \n",
      "299     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "300     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "301     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "302     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...   age  sex  trestbps   chol  fbs  \\\n",
      "0          0.0        0.0        1.0  ...  63.0  1.0     145.0  233.0  1.0   \n",
      "1          0.0        1.0        0.0  ...  67.0  1.0     160.0  286.0  0.0   \n",
      "2          0.0        1.0        0.0  ...  67.0  1.0     120.0  229.0  0.0   \n",
      "3          0.0        0.0        1.0  ...  37.0  1.0     130.0  250.0  0.0   \n",
      "4          1.0        0.0        0.0  ...  41.0  0.0     130.0  204.0  0.0   \n",
      "..         ...        ...        ...  ...   ...  ...       ...    ...  ...   \n",
      "298        0.0        1.0        0.0  ...  45.0  1.0     110.0  264.0  0.0   \n",
      "299        0.0        1.0        0.0  ...  68.0  1.0     144.0  193.0  1.0   \n",
      "300        0.0        1.0        0.0  ...  57.0  1.0     130.0  131.0  0.0   \n",
      "301        0.0        1.0        0.0  ...  57.0  0.0     130.0  236.0  0.0   \n",
      "302        1.0        0.0        0.0  ...  38.0  1.0     138.0  175.0  0.0   \n",
      "\n",
      "     thalach  exang  oldpeak   ca  num  \n",
      "0      150.0    0.0      2.3  0.0    0  \n",
      "1      108.0    1.0      1.5  3.0    2  \n",
      "2      129.0    1.0      2.6  2.0    1  \n",
      "3      187.0    0.0      3.5  0.0    0  \n",
      "4      172.0    0.0      1.4  0.0    0  \n",
      "..       ...    ...      ...  ...  ...  \n",
      "298    132.0    0.0      1.2  0.0    1  \n",
      "299    141.0    0.0      3.4  2.0    2  \n",
      "300    115.0    1.0      1.2  1.0    3  \n",
      "301    174.0    0.0      0.0  1.0    1  \n",
      "302    173.0    0.0      0.0  NaN    0  \n",
      "\n",
      "[303 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Use One-hot Encoder to use Hamming distance for KNN later\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_data = encoder.fit_transform(df_cleveland[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "cle_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "cle_encoded = pd.concat([cle_encoded, df_cleveland[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "cle_encoded = cle_encoded.drop('thal_nan', axis=1)\n",
    "\n",
    "print(cle_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7db017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data using MinMax Scaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(cle_encoded)\n",
    "scaled_cle = scaler.transform(cle_encoded)\n",
    "cle_encoded = pd.DataFrame(scaled_cle, columns=cle_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131b1913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cp_1.0', 'cp_2.0', 'cp_3.0', 'cp_4.0', 'restecg_0.0', 'restecg_1.0',\n",
      "       'restecg_2.0', 'slope_1.0', 'slope_2.0', 'slope_3.0', 'thal_3.0',\n",
      "       'thal_6.0', 'thal_7.0', 'age', 'sex', 'trestbps', 'chol', 'fbs',\n",
      "       'thalach', 'exang', 'oldpeak', 'ca', 'num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cle_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d5dcce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "3       0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "298     1.0     0.0     0.0     0.0          1.0          0.0          0.0   \n",
      "299     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "300     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "301     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "302     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...       age  sex  trestbps      chol  \\\n",
      "0          0.0        0.0        1.0  ...  0.708333  1.0  0.481132  0.244292   \n",
      "1          0.0        1.0        0.0  ...  0.791667  1.0  0.622642  0.365297   \n",
      "2          0.0        1.0        0.0  ...  0.791667  1.0  0.245283  0.235160   \n",
      "3          0.0        0.0        1.0  ...  0.166667  1.0  0.339623  0.283105   \n",
      "4          1.0        0.0        0.0  ...  0.250000  0.0  0.339623  0.178082   \n",
      "..         ...        ...        ...  ...       ...  ...       ...       ...   \n",
      "298        0.0        1.0        0.0  ...  0.333333  1.0  0.150943  0.315068   \n",
      "299        0.0        1.0        0.0  ...  0.812500  1.0  0.471698  0.152968   \n",
      "300        0.0        1.0        0.0  ...  0.583333  1.0  0.339623  0.011416   \n",
      "301        0.0        1.0        0.0  ...  0.583333  0.0  0.339623  0.251142   \n",
      "302        1.0        0.0        0.0  ...  0.187500  1.0  0.415094  0.111872   \n",
      "\n",
      "     fbs   thalach  exang   oldpeak        ca   num  \n",
      "0    1.0  0.603053    0.0  0.370968  0.000000  0.00  \n",
      "1    0.0  0.282443    1.0  0.241935  1.000000  0.50  \n",
      "2    0.0  0.442748    1.0  0.419355  0.666667  0.25  \n",
      "3    0.0  0.885496    0.0  0.564516  0.000000  0.00  \n",
      "4    0.0  0.770992    0.0  0.225806  0.000000  0.00  \n",
      "..   ...       ...    ...       ...       ...   ...  \n",
      "298  0.0  0.465649    0.0  0.193548  0.000000  0.25  \n",
      "299  1.0  0.534351    0.0  0.548387  0.666667  0.50  \n",
      "300  0.0  0.335878    1.0  0.193548  0.333333  0.75  \n",
      "301  0.0  0.786260    0.0  0.000000  0.333333  0.25  \n",
      "302  0.0  0.778626    0.0  0.000000  0.000000  0.00  \n",
      "\n",
      "[303 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed_cle = pd.DataFrame(imputer.fit_transform(cle_encoded))\n",
    "df_imputed_cle.columns = cle_encoded.columns[0:]\n",
    "\n",
    "print(df_imputed_cle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_cle.to_csv('Cleveland Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8192c34",
   "metadata": {},
   "source": [
    "## Hungarian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4176901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp trestbps chol fbs restecg thalach exang  oldpeak slope ca  \\\n",
      "0     28    1   2      130  132   0       2     185     0      0.0     ?  ?   \n",
      "1     29    1   2      120  243   0       0     160     0      0.0     ?  ?   \n",
      "2     29    1   2      140    ?   0       0     170     0      0.0     ?  ?   \n",
      "3     30    0   1      170  237   0       1     170     0      0.0     ?  ?   \n",
      "4     31    0   2      100  219   0       1     150     0      0.0     ?  ?   \n",
      "..   ...  ...  ..      ...  ...  ..     ...     ...   ...      ...   ... ..   \n",
      "289   52    1   4      160  331   0       0      94     1      2.5     ?  ?   \n",
      "290   54    0   3      130  294   0       1     100     1      0.0     2  ?   \n",
      "291   56    1   4      155  342   1       0     150     1      3.0     2  ?   \n",
      "292   58    0   2      180  393   0       0     110     1      1.0     2  ?   \n",
      "293   65    1   4      130  275   0       1     115     1      1.0     2  ?   \n",
      "\n",
      "    thal  num  \n",
      "0      ?    0  \n",
      "1      ?    0  \n",
      "2      ?    0  \n",
      "3      6    0  \n",
      "4      ?    0  \n",
      "..   ...  ...  \n",
      "289    ?    1  \n",
      "290    ?    1  \n",
      "291    ?    1  \n",
      "292    7    1  \n",
      "293    ?    1  \n",
      "\n",
      "[294 rows x 14 columns]\n",
      "Missing values: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_5616\\1664317974.py:8: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_hungarian.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "hungarian = 'data/processed.hungarian.data'\n",
    "\n",
    "df_hungarian = pd.read_csv(hungarian, header=None)\n",
    "\n",
    "df_hungarian.columns = columns_names\n",
    "print(df_hungarian)\n",
    "\n",
    "df_hungarian.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_hungarian.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d3e871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1  cp_2  cp_3  cp_4  restecg_0  restecg_1  restecg_2  restecg_nan  \\\n",
      "0     0.0   1.0   0.0   0.0        0.0        0.0        1.0          0.0   \n",
      "1     0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "2     0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "3     1.0   0.0   0.0   0.0        0.0        1.0        0.0          0.0   \n",
      "4     0.0   1.0   0.0   0.0        0.0        1.0        0.0          0.0   \n",
      "..    ...   ...   ...   ...        ...        ...        ...          ...   \n",
      "289   0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "290   0.0   0.0   1.0   0.0        0.0        1.0        0.0          0.0   \n",
      "291   0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "292   0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "293   0.0   0.0   0.0   1.0        0.0        1.0        0.0          0.0   \n",
      "\n",
      "     slope_1  slope_2  ...  age  sex  trestbps  chol  fbs  thalach  exang  \\\n",
      "0        0.0      0.0  ...   28    1       130   132    0      185      0   \n",
      "1        0.0      0.0  ...   29    1       120   243    0      160      0   \n",
      "2        0.0      0.0  ...   29    1       140   NaN    0      170      0   \n",
      "3        0.0      0.0  ...   30    0       170   237    0      170      0   \n",
      "4        0.0      0.0  ...   31    0       100   219    0      150      0   \n",
      "..       ...      ...  ...  ...  ...       ...   ...  ...      ...    ...   \n",
      "289      0.0      0.0  ...   52    1       160   331    0       94      1   \n",
      "290      0.0      1.0  ...   54    0       130   294    0      100      1   \n",
      "291      0.0      1.0  ...   56    1       155   342    1      150      1   \n",
      "292      0.0      1.0  ...   58    0       180   393    0      110      1   \n",
      "293      0.0      1.0  ...   65    1       130   275    0      115      1   \n",
      "\n",
      "     oldpeak   ca num  \n",
      "0        0.0  NaN   0  \n",
      "1        0.0  NaN   0  \n",
      "2        0.0  NaN   0  \n",
      "3        0.0  NaN   0  \n",
      "4        0.0  NaN   0  \n",
      "..       ...  ...  ..  \n",
      "289      2.5  NaN   1  \n",
      "290      0.0  NaN   1  \n",
      "291      3.0  NaN   1  \n",
      "292      1.0  NaN   1  \n",
      "293      1.0  NaN   1  \n",
      "\n",
      "[294 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_data = encoder.fit_transform(df_hungarian[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "hung_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "hung_encoded = pd.concat([hung_encoded, df_hungarian[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "\n",
    "print(hung_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e79205",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cp_1', 'cp_2', 'cp_3', 'cp_4', 'restecg_0', 'restecg_1', 'restecg_2',\n",
      "       'restecg_nan', 'slope_1', 'slope_2', 'slope_3', 'slope_nan', 'thal_3',\n",
      "       'thal_6', 'thal_7', 'thal_nan', 'age', 'sex', 'trestbps', 'chol', 'fbs',\n",
      "       'thalach', 'exang', 'oldpeak', 'ca', 'num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hung_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6cb5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "hung_encoded = hung_encoded.drop(['restecg_nan','slope_nan','thal_nan'], axis=1)\n",
    "hung_encoded.columns = cle_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "222c67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data using MinMax Scaler\n",
    "\n",
    "scaler.fit(hung_encoded)\n",
    "scaled_hung = scaler.transform(hung_encoded)\n",
    "hung_encoded = pd.DataFrame(scaled_hung, columns=hung_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d255b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     1.0     0.0     0.0          1.0          0.0          0.0   \n",
      "2       0.0     1.0     0.0     0.0          1.0          0.0          0.0   \n",
      "3       1.0     0.0     0.0     0.0          0.0          1.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          1.0          0.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "289     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "290     0.0     0.0     1.0     0.0          0.0          1.0          0.0   \n",
      "291     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "292     0.0     1.0     0.0     0.0          1.0          0.0          0.0   \n",
      "293     0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...       age  sex  trestbps      chol  \\\n",
      "0          0.0        0.0        0.0  ...  0.000000  1.0  0.351852  0.090734   \n",
      "1          0.0        0.0        0.0  ...  0.026316  1.0  0.259259  0.305019   \n",
      "2          0.0        0.0        0.0  ...  0.026316  1.0  0.444444  0.226941   \n",
      "3          0.0        0.0        0.0  ...  0.052632  0.0  0.722222  0.293436   \n",
      "4          0.0        0.0        0.0  ...  0.078947  0.0  0.074074  0.258687   \n",
      "..         ...        ...        ...  ...       ...  ...       ...       ...   \n",
      "289        0.0        0.0        0.0  ...  0.631579  1.0  0.629630  0.474903   \n",
      "290        0.0        1.0        0.0  ...  0.684211  0.0  0.351852  0.403475   \n",
      "291        0.0        1.0        0.0  ...  0.736842  1.0  0.583333  0.496139   \n",
      "292        0.0        1.0        0.0  ...  0.789474  0.0  0.814815  0.594595   \n",
      "293        0.0        1.0        0.0  ...  0.973684  1.0  0.351852  0.366795   \n",
      "\n",
      "     fbs   thalach  exang  oldpeak        ca  num  \n",
      "0    0.0  0.953704    0.0      0.0  0.000000  0.0  \n",
      "1    0.0  0.722222    0.0      0.0  0.000000  0.0  \n",
      "2    0.0  0.814815    0.0      0.0  0.000000  0.0  \n",
      "3    0.0  0.814815    0.0      0.0  0.133333  0.0  \n",
      "4    0.0  0.629630    0.0      0.0  0.066667  0.0  \n",
      "..   ...       ...    ...      ...       ...  ...  \n",
      "289  0.0  0.111111    1.0      0.5  0.400000  1.0  \n",
      "290  0.0  0.166667    1.0      0.0  0.200000  1.0  \n",
      "291  1.0  0.629630    1.0      0.6  0.533333  1.0  \n",
      "292  0.0  0.259259    1.0      0.2  0.266667  1.0  \n",
      "293  0.0  0.305556    1.0      0.2  0.400000  1.0  \n",
      "\n",
      "[294 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(df_imputed_cle)\n",
    "\n",
    "df_imputed_hungarian = pd.DataFrame(imputer.transform(hung_encoded), columns=hung_encoded.columns)\n",
    "print(df_imputed_hungarian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41793a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_hungarian.to_csv('Hungarian Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2803c16",
   "metadata": {},
   "source": [
    "## Switzerland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5452ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp trestbps  chol fbs restecg thalach exang oldpeak slope ca  \\\n",
      "0     32    1   1       95     0   ?       0     127     0      .7     1  ?   \n",
      "1     34    1   4      115     0   ?       ?     154     0      .2     1  ?   \n",
      "2     35    1   4        ?     0   ?       0     130     1       ?     ?  ?   \n",
      "3     36    1   4      110     0   ?       0     125     1       1     2  ?   \n",
      "4     38    0   4      105     0   ?       0     166     0     2.8     1  ?   \n",
      "..   ...  ...  ..      ...   ...  ..     ...     ...   ...     ...   ... ..   \n",
      "118   70    1   4      115     0   0       1      92     1       0     2  ?   \n",
      "119   70    1   4      140     0   1       0     157     1       2     2  ?   \n",
      "120   72    1   3      160     0   ?       2     114     0     1.6     2  2   \n",
      "121   73    0   3      160     0   0       1     121     0       0     1  ?   \n",
      "122   74    1   2      145     0   ?       1     123     0     1.3     1  ?   \n",
      "\n",
      "    thal  num  \n",
      "0      ?    1  \n",
      "1      ?    1  \n",
      "2      7    3  \n",
      "3      6    1  \n",
      "4      ?    2  \n",
      "..   ...  ...  \n",
      "118    7    1  \n",
      "119    7    3  \n",
      "120    ?    0  \n",
      "121    3    1  \n",
      "122    ?    1  \n",
      "\n",
      "[123 rows x 14 columns]\n",
      "Missing values: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_5616\\3668511862.py:8: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_switzerland.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "switzerland = 'data/processed.switzerland.data'\n",
    "\n",
    "df_switzerland = pd.read_csv(switzerland, header=None)\n",
    "\n",
    "df_switzerland.columns = columns_names\n",
    "print(df_switzerland)\n",
    "\n",
    "df_switzerland.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_switzerland.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12ff638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1  cp_2  cp_3  cp_4  restecg_0  restecg_1  restecg_2  restecg_nan  \\\n",
      "0     1.0   0.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "1     0.0   0.0   0.0   1.0        0.0        0.0        0.0          1.0   \n",
      "2     0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "3     0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "4     0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "..    ...   ...   ...   ...        ...        ...        ...          ...   \n",
      "118   0.0   0.0   0.0   1.0        0.0        1.0        0.0          0.0   \n",
      "119   0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "120   0.0   0.0   1.0   0.0        0.0        0.0        1.0          0.0   \n",
      "121   0.0   0.0   1.0   0.0        0.0        1.0        0.0          0.0   \n",
      "122   0.0   1.0   0.0   0.0        0.0        1.0        0.0          0.0   \n",
      "\n",
      "     slope_1  slope_2  ...  age  sex  trestbps  chol  fbs  thalach  exang  \\\n",
      "0        1.0      0.0  ...   32    1        95     0  NaN      127      0   \n",
      "1        1.0      0.0  ...   34    1       115     0  NaN      154      0   \n",
      "2        0.0      0.0  ...   35    1       NaN     0  NaN      130      1   \n",
      "3        0.0      1.0  ...   36    1       110     0  NaN      125      1   \n",
      "4        1.0      0.0  ...   38    0       105     0  NaN      166      0   \n",
      "..       ...      ...  ...  ...  ...       ...   ...  ...      ...    ...   \n",
      "118      0.0      1.0  ...   70    1       115     0    0       92      1   \n",
      "119      0.0      1.0  ...   70    1       140     0    1      157      1   \n",
      "120      0.0      1.0  ...   72    1       160     0  NaN      114      0   \n",
      "121      1.0      0.0  ...   73    0       160     0    0      121      0   \n",
      "122      1.0      0.0  ...   74    1       145     0  NaN      123      0   \n",
      "\n",
      "     oldpeak   ca  num  \n",
      "0         .7  NaN    1  \n",
      "1         .2  NaN    1  \n",
      "2        NaN  NaN    3  \n",
      "3          1  NaN    1  \n",
      "4        2.8  NaN    2  \n",
      "..       ...  ...  ...  \n",
      "118        0  NaN    1  \n",
      "119        2  NaN    3  \n",
      "120      1.6    2    0  \n",
      "121        0  NaN    1  \n",
      "122      1.3  NaN    1  \n",
      "\n",
      "[123 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "encoded_data = encoder.fit_transform(df_switzerland[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "swi_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "swi_encoded = pd.concat([swi_encoded, df_switzerland[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "\n",
    "print(swi_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed86b5bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cp_1', 'cp_2', 'cp_3', 'cp_4', 'restecg_0', 'restecg_1', 'restecg_2',\n",
      "       'restecg_nan', 'slope_1', 'slope_2', 'slope_3', 'slope_nan', 'thal_3',\n",
      "       'thal_6', 'thal_7', 'thal_nan', 'age', 'sex', 'trestbps', 'chol', 'fbs',\n",
      "       'thalach', 'exang', 'oldpeak', 'ca', 'num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(swi_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9eb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_encoded = swi_encoded.drop(['restecg_nan','slope_nan','thal_nan'], axis=1)\n",
    "swi_encoded.columns = cle_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f7137f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data using MinMax Scaler\n",
    "\n",
    "scaler.fit(swi_encoded)\n",
    "scaled_swi = scaler.transform(swi_encoded)\n",
    "swi_encoded = pd.DataFrame(scaled_swi, columns=swi_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13f88ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          1.0          0.0          0.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          0.0   \n",
      "2       0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "3       0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "4       0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "118     0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "119     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "120     0.0     0.0     1.0     0.0          0.0          0.0          1.0   \n",
      "121     0.0     0.0     1.0     0.0          0.0          1.0          0.0   \n",
      "122     0.0     1.0     0.0     0.0          0.0          1.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...       age  sex  trestbps  chol  fbs  \\\n",
      "0          1.0        0.0        0.0  ...  0.000000  1.0  0.125000   0.0  0.0   \n",
      "1          1.0        0.0        0.0  ...  0.047619  1.0  0.291667   0.0  0.0   \n",
      "2          0.0        0.0        0.0  ...  0.071429  1.0  0.320755   0.0  0.0   \n",
      "3          0.0        1.0        0.0  ...  0.095238  1.0  0.250000   0.0  0.2   \n",
      "4          1.0        0.0        0.0  ...  0.142857  0.0  0.208333   0.0  0.0   \n",
      "..         ...        ...        ...  ...       ...  ...       ...   ...  ...   \n",
      "118        0.0        1.0        0.0  ...  0.904762  1.0  0.291667   0.0  0.0   \n",
      "119        0.0        1.0        0.0  ...  0.904762  1.0  0.500000   0.0  1.0   \n",
      "120        0.0        1.0        0.0  ...  0.952381  1.0  0.666667   0.0  0.2   \n",
      "121        1.0        0.0        0.0  ...  0.976190  0.0  0.666667   0.0  0.0   \n",
      "122        1.0        0.0        0.0  ...  1.000000  1.0  0.541667   0.0  0.2   \n",
      "\n",
      "      thalach  exang   oldpeak        ca   num  \n",
      "0    0.549180    0.0  0.523810  0.266667  0.25  \n",
      "1    0.770492    0.0  0.444444  0.066667  0.25  \n",
      "2    0.573770    1.0  0.496774  0.333333  0.75  \n",
      "3    0.532787    1.0  0.571429  0.000000  0.25  \n",
      "4    0.868852    0.0  0.857143  0.266667  0.50  \n",
      "..        ...    ...       ...       ...   ...  \n",
      "118  0.262295    1.0  0.412698  0.600000  0.25  \n",
      "119  0.795082    1.0  0.730159  0.600000  0.75  \n",
      "120  0.442623    0.0  0.666667  1.000000  0.00  \n",
      "121  0.500000    0.0  0.412698  0.133333  0.25  \n",
      "122  0.516393    0.0  0.619048  0.133333  0.25  \n",
      "\n",
      "[123 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df_imputed_swi = pd.DataFrame(imputer.transform(swi_encoded), columns=swi_encoded.columns)\n",
    "\n",
    "print(df_imputed_swi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc29fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_swi.to_csv('Switzerland Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb22fd0",
   "metadata": {},
   "source": [
    "## Long Beach, VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec62962e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp trestbps chol fbs  restecg thalach exang oldpeak slope ca  \\\n",
      "0     63    1   4      140  260   0        1     112     1       3     2  ?   \n",
      "1     44    1   4      130  209   0        1     127     0       0     ?  ?   \n",
      "2     60    1   4      132  218   0        1     140     1     1.5     3  ?   \n",
      "3     55    1   4      142  228   0        1     149     1     2.5     1  ?   \n",
      "4     66    1   3      110  213   1        2      99     1     1.3     2  ?   \n",
      "..   ...  ...  ..      ...  ...  ..      ...     ...   ...     ...   ... ..   \n",
      "195   54    0   4      127  333   1        1     154     0       0     ?  ?   \n",
      "196   62    1   1        ?  139   0        1       ?     ?       ?     ?  ?   \n",
      "197   55    1   4      122  223   1        1     100     0       0     ?  ?   \n",
      "198   58    1   4        ?  385   1        2       ?     ?       ?     ?  ?   \n",
      "199   62    1   2      120  254   0        2      93     1       0     ?  ?   \n",
      "\n",
      "    thal  num  \n",
      "0      ?    2  \n",
      "1      ?    0  \n",
      "2      ?    2  \n",
      "3      ?    1  \n",
      "4      ?    0  \n",
      "..   ...  ...  \n",
      "195    ?    1  \n",
      "196    ?    0  \n",
      "197    6    2  \n",
      "198    ?    0  \n",
      "199    ?    1  \n",
      "\n",
      "[200 rows x 14 columns]\n",
      "Missing values: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_5616\\1151154779.py:7: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_va.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "va = 'data/processed.va.data'\n",
    "\n",
    "df_va = pd.read_csv(va, header=None)\n",
    "df_va.columns = columns_names\n",
    "print(df_va)\n",
    "\n",
    "df_va.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_va.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da41866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1  cp_2  cp_3  cp_4  restecg_0  restecg_1  restecg_2  slope_1  \\\n",
      "0     0.0   0.0   0.0   1.0        0.0        1.0        0.0      0.0   \n",
      "1     0.0   0.0   0.0   1.0        0.0        1.0        0.0      0.0   \n",
      "2     0.0   0.0   0.0   1.0        0.0        1.0        0.0      0.0   \n",
      "3     0.0   0.0   0.0   1.0        0.0        1.0        0.0      1.0   \n",
      "4     0.0   0.0   1.0   0.0        0.0        0.0        1.0      0.0   \n",
      "..    ...   ...   ...   ...        ...        ...        ...      ...   \n",
      "195   0.0   0.0   0.0   1.0        0.0        1.0        0.0      0.0   \n",
      "196   1.0   0.0   0.0   0.0        0.0        1.0        0.0      0.0   \n",
      "197   0.0   0.0   0.0   1.0        0.0        1.0        0.0      0.0   \n",
      "198   0.0   0.0   0.0   1.0        0.0        0.0        1.0      0.0   \n",
      "199   0.0   1.0   0.0   0.0        0.0        0.0        1.0      0.0   \n",
      "\n",
      "     slope_2  slope_3  ...  age  sex  trestbps  chol  fbs  thalach  exang  \\\n",
      "0        1.0      0.0  ...   63    1       140   260    0      112      1   \n",
      "1        0.0      0.0  ...   44    1       130   209    0      127      0   \n",
      "2        0.0      1.0  ...   60    1       132   218    0      140      1   \n",
      "3        0.0      0.0  ...   55    1       142   228    0      149      1   \n",
      "4        1.0      0.0  ...   66    1       110   213    1       99      1   \n",
      "..       ...      ...  ...  ...  ...       ...   ...  ...      ...    ...   \n",
      "195      0.0      0.0  ...   54    0       127   333    1      154      0   \n",
      "196      0.0      0.0  ...   62    1       NaN   139    0      NaN    NaN   \n",
      "197      0.0      0.0  ...   55    1       122   223    1      100      0   \n",
      "198      0.0      0.0  ...   58    1       NaN   385    1      NaN    NaN   \n",
      "199      0.0      0.0  ...   62    1       120   254    0       93      1   \n",
      "\n",
      "    oldpeak   ca num  \n",
      "0         3  NaN   2  \n",
      "1         0  NaN   0  \n",
      "2       1.5  NaN   2  \n",
      "3       2.5  NaN   1  \n",
      "4       1.3  NaN   0  \n",
      "..      ...  ...  ..  \n",
      "195       0  NaN   1  \n",
      "196     NaN  NaN   0  \n",
      "197       0  NaN   2  \n",
      "198     NaN  NaN   0  \n",
      "199       0  NaN   1  \n",
      "\n",
      "[200 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "encoded_data = encoder.fit_transform(df_va[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "va_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "va_encoded = pd.concat([va_encoded, df_va[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "\n",
    "print(va_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5df908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cp_1', 'cp_2', 'cp_3', 'cp_4', 'restecg_0', 'restecg_1', 'restecg_2',\n",
      "       'slope_1', 'slope_2', 'slope_3', 'slope_nan', 'thal_3', 'thal_6',\n",
      "       'thal_7', 'thal_nan', 'age', 'sex', 'trestbps', 'chol', 'fbs',\n",
      "       'thalach', 'exang', 'oldpeak', 'ca', 'num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(va_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21685ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_encoded = va_encoded.drop(['slope_nan','thal_nan'], axis=1)\n",
    "va_encoded.columns = cle_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cc8e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data using MinMax Scaler\n",
    "\n",
    "scaler.fit(va_encoded)\n",
    "scaled_va = scaler.transform(va_encoded)\n",
    "va_encoded = pd.DataFrame(scaled_va, columns=va_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ed33c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "3       0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "4       0.0     0.0     1.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "195     0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "196     1.0     0.0     0.0     0.0          0.0          1.0          0.0   \n",
      "197     0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "198     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "199     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...       age  sex  trestbps      chol  \\\n",
      "0          0.0        1.0        0.0  ...  0.666667  1.0  0.736842  0.567686   \n",
      "1          0.0        0.0        0.0  ...  0.214286  1.0  0.684211  0.456332   \n",
      "2          0.0        0.0        1.0  ...  0.595238  1.0  0.694737  0.475983   \n",
      "3          1.0        0.0        0.0  ...  0.476190  1.0  0.747368  0.497817   \n",
      "4          0.0        1.0        0.0  ...  0.738095  1.0  0.578947  0.465066   \n",
      "..         ...        ...        ...  ...       ...  ...       ...       ...   \n",
      "195        0.0        0.0        0.0  ...  0.452381  0.0  0.668421  0.727074   \n",
      "196        0.0        0.0        0.0  ...  0.642857  1.0  0.439623  0.303493   \n",
      "197        0.0        0.0        0.0  ...  0.476190  1.0  0.642105  0.486900   \n",
      "198        0.0        0.0        0.0  ...  0.547619  1.0  0.352830  0.840611   \n",
      "199        0.0        0.0        0.0  ...  0.642857  1.0  0.631579  0.554585   \n",
      "\n",
      "     fbs   thalach  exang   oldpeak        ca   num  \n",
      "0    0.0  0.387387    1.0  0.777778  0.600000  0.50  \n",
      "1    0.0  0.522523    0.0  0.111111  0.200000  0.00  \n",
      "2    0.0  0.639640    1.0  0.444444  0.266667  0.50  \n",
      "3    0.0  0.720721    1.0  0.666667  0.266667  0.25  \n",
      "4    1.0  0.270270    1.0  0.400000  0.066667  0.00  \n",
      "..   ...       ...    ...       ...       ...   ...  \n",
      "195  1.0  0.765766    0.0  0.111111  0.266667  0.25  \n",
      "196  0.0  0.574046    0.4  0.319355  0.066667  0.00  \n",
      "197  1.0  0.279279    0.0  0.111111  0.466667  0.50  \n",
      "198  1.0  0.491603    1.0  0.251613  0.386667  0.00  \n",
      "199  0.0  0.216216    1.0  0.111111  0.200000  0.25  \n",
      "\n",
      "[200 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df_imputed_va = pd.DataFrame(imputer.transform(va_encoded), columns=va_encoded.columns)\n",
    "\n",
    "print(df_imputed_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_va.to_csv('Virginia Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d86e60",
   "metadata": {},
   "source": [
    "## Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ba9c89b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "3       0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "915     0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "916     1.0     0.0     0.0     0.0          0.0          1.0          0.0   \n",
      "917     0.0     0.0     0.0     1.0          0.0          1.0          0.0   \n",
      "918     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "919     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...       age  sex  trestbps      chol  \\\n",
      "0          0.0        0.0        1.0  ...  0.708333  1.0  0.481132  0.244292   \n",
      "1          0.0        1.0        0.0  ...  0.791667  1.0  0.622642  0.365297   \n",
      "2          0.0        1.0        0.0  ...  0.791667  1.0  0.245283  0.235160   \n",
      "3          0.0        0.0        1.0  ...  0.166667  1.0  0.339623  0.283105   \n",
      "4          1.0        0.0        0.0  ...  0.250000  0.0  0.339623  0.178082   \n",
      "..         ...        ...        ...  ...       ...  ...       ...       ...   \n",
      "915        0.0        0.0        0.0  ...  0.452381  0.0  0.668421  0.727074   \n",
      "916        0.0        0.0        0.0  ...  0.642857  1.0       NaN  0.303493   \n",
      "917        0.0        0.0        0.0  ...  0.476190  1.0  0.642105  0.486900   \n",
      "918        0.0        0.0        0.0  ...  0.547619  1.0       NaN  0.840611   \n",
      "919        0.0        0.0        0.0  ...  0.642857  1.0  0.631579  0.554585   \n",
      "\n",
      "     fbs   thalach  exang   oldpeak        ca   num  \n",
      "0    1.0  0.603053    0.0  0.370968  0.000000  0.00  \n",
      "1    0.0  0.282443    1.0  0.241935  1.000000  0.50  \n",
      "2    0.0  0.442748    1.0  0.419355  0.666667  0.25  \n",
      "3    0.0  0.885496    0.0  0.564516  0.000000  0.00  \n",
      "4    0.0  0.770992    0.0  0.225806  0.000000  0.00  \n",
      "..   ...       ...    ...       ...       ...   ...  \n",
      "915  1.0  0.765766    0.0  0.111111       NaN  0.25  \n",
      "916  0.0       NaN    NaN       NaN       NaN  0.00  \n",
      "917  1.0  0.279279    0.0  0.111111       NaN  0.50  \n",
      "918  1.0       NaN    NaN       NaN       NaN  0.00  \n",
      "919  0.0  0.216216    1.0  0.111111       NaN  0.25  \n",
      "\n",
      "[920 rows x 23 columns]\n",
      "Missing values: 617\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([cle_encoded, hung_encoded, swi_encoded, va_encoded], ignore_index=True)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "print(combined_df)\n",
    "\n",
    "count_missing = combined_df.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa4f468b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'int', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\_encode.py:135\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse)\u001b[0m\n\u001b[0;32m    133\u001b[0m uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n\u001b[1;32m--> 135\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m uniques\u001b[38;5;241m.\u001b[39mextend(missing_values\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrestecg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mslope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:488\u001b[0m, in \u001b[0;36mOneHotEncoder.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03mFit OneHotEncoder to X, then transform X.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    returned.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[1;32m--> 488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:461\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03mFit OneHotEncoder to X.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03m    Fitted encoder.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_idx_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_drop_idx()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:94\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[1;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[0;32m     92\u001b[0m Xi \u001b[38;5;241m=\u001b[39m X_list[i]\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     cats \u001b[38;5;241m=\u001b[39m \u001b[43m_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     cats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories[i], dtype\u001b[38;5;241m=\u001b[39mXi\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\_encode.py:31\u001b[0m, in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Only provided if `return_inverse` is True.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unique_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[0;32m     33\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse)\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\_encode.py:140\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input to be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques, _map_to_integer(values, uniques)\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'int', 'str']"
     ]
    }
   ],
   "source": [
    "encoded_data = encoder.fit_transform(combined_df[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "#df_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "#df_encoded = pd.concat([df_encoded, combined_df[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "\n",
    "#print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4373da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1069a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02fe27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78eaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('Combined Imputed Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
