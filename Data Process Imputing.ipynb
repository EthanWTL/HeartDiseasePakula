{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed05285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2c3ed",
   "metadata": {},
   "source": [
    "# Local data for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37651f",
   "metadata": {},
   "source": [
    "## Cleveland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e281b4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
      "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
      "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
      "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
      "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
      "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
      "\n",
      "     slope   ca thal  num  \n",
      "0      3.0  0.0  6.0    0  \n",
      "1      2.0  3.0  3.0    2  \n",
      "2      2.0  2.0  7.0    1  \n",
      "3      3.0  0.0  3.0    0  \n",
      "4      1.0  0.0  3.0    0  \n",
      "..     ...  ...  ...  ...  \n",
      "298    2.0  0.0  7.0    1  \n",
      "299    2.0  2.0  7.0    2  \n",
      "300    2.0  1.0  7.0    3  \n",
      "301    2.0  1.0  3.0    1  \n",
      "302    1.0    ?  3.0    0  \n",
      "\n",
      "[303 rows x 14 columns]\n",
      "Missing values: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_6792\\3715974877.py:11: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_cleveland.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cleveland = 'data/processed.cleveland.data'\n",
    "\n",
    "df_cleveland = pd.read_csv(cleveland, header=None)\n",
    "\n",
    "columns_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "df_cleveland.columns = columns_names\n",
    "print(df_cleveland)\n",
    "\n",
    "df_cleveland.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_cleveland.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d7a145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "3       0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "298     1.0     0.0     0.0     0.0          1.0          0.0          0.0   \n",
      "299     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "300     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "301     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "302     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...   age  sex  trestbps   chol  fbs  \\\n",
      "0          0.0        0.0        1.0  ...  63.0  1.0     145.0  233.0  1.0   \n",
      "1          0.0        1.0        0.0  ...  67.0  1.0     160.0  286.0  0.0   \n",
      "2          0.0        1.0        0.0  ...  67.0  1.0     120.0  229.0  0.0   \n",
      "3          0.0        0.0        1.0  ...  37.0  1.0     130.0  250.0  0.0   \n",
      "4          1.0        0.0        0.0  ...  41.0  0.0     130.0  204.0  0.0   \n",
      "..         ...        ...        ...  ...   ...  ...       ...    ...  ...   \n",
      "298        0.0        1.0        0.0  ...  45.0  1.0     110.0  264.0  0.0   \n",
      "299        0.0        1.0        0.0  ...  68.0  1.0     144.0  193.0  1.0   \n",
      "300        0.0        1.0        0.0  ...  57.0  1.0     130.0  131.0  0.0   \n",
      "301        0.0        1.0        0.0  ...  57.0  0.0     130.0  236.0  0.0   \n",
      "302        1.0        0.0        0.0  ...  38.0  1.0     138.0  175.0  0.0   \n",
      "\n",
      "     thalach  exang  oldpeak   ca  num  \n",
      "0      150.0    0.0      2.3  0.0    0  \n",
      "1      108.0    1.0      1.5  3.0    2  \n",
      "2      129.0    1.0      2.6  2.0    1  \n",
      "3      187.0    0.0      3.5  0.0    0  \n",
      "4      172.0    0.0      1.4  0.0    0  \n",
      "..       ...    ...      ...  ...  ...  \n",
      "298    132.0    0.0      1.2  0.0    1  \n",
      "299    141.0    0.0      3.4  2.0    2  \n",
      "300    115.0    1.0      1.2  1.0    3  \n",
      "301    174.0    0.0      0.0  1.0    1  \n",
      "302    173.0    0.0      0.0  NaN    0  \n",
      "\n",
      "[303 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Use One-hot Encoder to use Hamming distance for KNN later\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_data = encoder.fit_transform(df_cleveland[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "cle_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "cle_encoded = pd.concat([cle_encoded, df_cleveland[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "cle_encoded = cle_encoded.drop('thal_nan', axis=1)\n",
    "\n",
    "print(cle_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d5dcce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "3       0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "298     1.0     0.0     0.0     0.0          1.0          0.0          0.0   \n",
      "299     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "300     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "301     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "302     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...   age  sex  trestbps   chol  fbs  \\\n",
      "0          0.0        0.0        1.0  ...  63.0  1.0     145.0  233.0  1.0   \n",
      "1          0.0        1.0        0.0  ...  67.0  1.0     160.0  286.0  0.0   \n",
      "2          0.0        1.0        0.0  ...  67.0  1.0     120.0  229.0  0.0   \n",
      "3          0.0        0.0        1.0  ...  37.0  1.0     130.0  250.0  0.0   \n",
      "4          1.0        0.0        0.0  ...  41.0  0.0     130.0  204.0  0.0   \n",
      "..         ...        ...        ...  ...   ...  ...       ...    ...  ...   \n",
      "298        0.0        1.0        0.0  ...  45.0  1.0     110.0  264.0  0.0   \n",
      "299        0.0        1.0        0.0  ...  68.0  1.0     144.0  193.0  1.0   \n",
      "300        0.0        1.0        0.0  ...  57.0  1.0     130.0  131.0  0.0   \n",
      "301        0.0        1.0        0.0  ...  57.0  0.0     130.0  236.0  0.0   \n",
      "302        1.0        0.0        0.0  ...  38.0  1.0     138.0  175.0  0.0   \n",
      "\n",
      "     thalach  exang  oldpeak   ca  num  \n",
      "0      150.0    0.0      2.3  0.0  0.0  \n",
      "1      108.0    1.0      1.5  3.0  2.0  \n",
      "2      129.0    1.0      2.6  2.0  1.0  \n",
      "3      187.0    0.0      3.5  0.0  0.0  \n",
      "4      172.0    0.0      1.4  0.0  0.0  \n",
      "..       ...    ...      ...  ...  ...  \n",
      "298    132.0    0.0      1.2  0.0  1.0  \n",
      "299    141.0    0.0      3.4  2.0  2.0  \n",
      "300    115.0    1.0      1.2  1.0  3.0  \n",
      "301    174.0    0.0      0.0  1.0  1.0  \n",
      "302    173.0    0.0      0.0  0.0  0.0  \n",
      "\n",
      "[303 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed_cle = pd.DataFrame(imputer.fit_transform(cle_encoded))\n",
    "df_imputed_cle.columns = cle_encoded.columns[0:]\n",
    "\n",
    "print(df_imputed_cle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87fcf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_cle.to_csv('Cleveland Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8192c34",
   "metadata": {},
   "source": [
    "## Hungarian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4176901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp trestbps chol fbs restecg thalach exang  oldpeak slope ca  \\\n",
      "0     28    1   2      130  132   0       2     185     0      0.0     ?  ?   \n",
      "1     29    1   2      120  243   0       0     160     0      0.0     ?  ?   \n",
      "2     29    1   2      140    ?   0       0     170     0      0.0     ?  ?   \n",
      "3     30    0   1      170  237   0       1     170     0      0.0     ?  ?   \n",
      "4     31    0   2      100  219   0       1     150     0      0.0     ?  ?   \n",
      "..   ...  ...  ..      ...  ...  ..     ...     ...   ...      ...   ... ..   \n",
      "289   52    1   4      160  331   0       0      94     1      2.5     ?  ?   \n",
      "290   54    0   3      130  294   0       1     100     1      0.0     2  ?   \n",
      "291   56    1   4      155  342   1       0     150     1      3.0     2  ?   \n",
      "292   58    0   2      180  393   0       0     110     1      1.0     2  ?   \n",
      "293   65    1   4      130  275   0       1     115     1      1.0     2  ?   \n",
      "\n",
      "    thal  num  \n",
      "0      ?    0  \n",
      "1      ?    0  \n",
      "2      ?    0  \n",
      "3      6    0  \n",
      "4      ?    0  \n",
      "..   ...  ...  \n",
      "289    ?    1  \n",
      "290    ?    1  \n",
      "291    ?    1  \n",
      "292    7    1  \n",
      "293    ?    1  \n",
      "\n",
      "[294 rows x 14 columns]\n",
      "Missing values: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_6792\\1664317974.py:8: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_hungarian.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "hungarian = 'data/processed.hungarian.data'\n",
    "\n",
    "df_hungarian = pd.read_csv(hungarian, header=None)\n",
    "\n",
    "df_hungarian.columns = columns_names\n",
    "print(df_hungarian)\n",
    "\n",
    "df_hungarian.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_hungarian.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93d3e871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1  cp_2  cp_3  cp_4  restecg_0  restecg_1  restecg_2  restecg_nan  \\\n",
      "0     0.0   1.0   0.0   0.0        0.0        0.0        1.0          0.0   \n",
      "1     0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "2     0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "3     1.0   0.0   0.0   0.0        0.0        1.0        0.0          0.0   \n",
      "4     0.0   1.0   0.0   0.0        0.0        1.0        0.0          0.0   \n",
      "..    ...   ...   ...   ...        ...        ...        ...          ...   \n",
      "289   0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "290   0.0   0.0   1.0   0.0        0.0        1.0        0.0          0.0   \n",
      "291   0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "292   0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "293   0.0   0.0   0.0   1.0        0.0        1.0        0.0          0.0   \n",
      "\n",
      "     slope_1  slope_2  ...  age  sex  trestbps  chol  fbs  thalach  exang  \\\n",
      "0        0.0      0.0  ...   28    1       130   132    0      185      0   \n",
      "1        0.0      0.0  ...   29    1       120   243    0      160      0   \n",
      "2        0.0      0.0  ...   29    1       140   NaN    0      170      0   \n",
      "3        0.0      0.0  ...   30    0       170   237    0      170      0   \n",
      "4        0.0      0.0  ...   31    0       100   219    0      150      0   \n",
      "..       ...      ...  ...  ...  ...       ...   ...  ...      ...    ...   \n",
      "289      0.0      0.0  ...   52    1       160   331    0       94      1   \n",
      "290      0.0      1.0  ...   54    0       130   294    0      100      1   \n",
      "291      0.0      1.0  ...   56    1       155   342    1      150      1   \n",
      "292      0.0      1.0  ...   58    0       180   393    0      110      1   \n",
      "293      0.0      1.0  ...   65    1       130   275    0      115      1   \n",
      "\n",
      "     oldpeak   ca num  \n",
      "0        0.0  NaN   0  \n",
      "1        0.0  NaN   0  \n",
      "2        0.0  NaN   0  \n",
      "3        0.0  NaN   0  \n",
      "4        0.0  NaN   0  \n",
      "..       ...  ...  ..  \n",
      "289      2.5  NaN   1  \n",
      "290      0.0  NaN   1  \n",
      "291      3.0  NaN   1  \n",
      "292      1.0  NaN   1  \n",
      "293      1.0  NaN   1  \n",
      "\n",
      "[294 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_data = encoder.fit_transform(df_hungarian[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "hung_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "hung_encoded = pd.concat([hung_encoded, df_hungarian[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "\n",
    "print(hung_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e79205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cp_1', 'cp_2', 'cp_3', 'cp_4', 'restecg_0', 'restecg_1', 'restecg_2',\n",
      "       'restecg_nan', 'slope_1', 'slope_2', 'slope_3', 'slope_nan', 'thal_3',\n",
      "       'thal_6', 'thal_7', 'thal_nan', 'age', 'sex', 'trestbps', 'chol', 'fbs',\n",
      "       'thalach', 'exang', 'oldpeak', 'ca', 'num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hung_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d255b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- cp_1\n",
      "- cp_2\n",
      "- cp_3\n",
      "- cp_4\n",
      "- restecg_0\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- cp_1.0\n",
      "- cp_2.0\n",
      "- cp_3.0\n",
      "- cp_4.0\n",
      "- restecg_0.0\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 26 features, but KNNImputer is expecting 23 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m imputer \u001b[38;5;241m=\u001b[39m KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      2\u001b[0m imputer\u001b[38;5;241m.\u001b[39mfit(df_imputed_cle)\n\u001b[1;32m----> 4\u001b[0m df_imputed_hungarian \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhung_encoded\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mhung_encoded\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_imputed_hungarian)\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\impute\\_knn.py:245\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 245\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m mask \u001b[38;5;241m=\u001b[39m _get_mask(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values)\n\u001b[0;32m    255\u001b[0m mask_fit_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_fit_X\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 26 features, but KNNImputer is expecting 23 features as input."
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(df_imputed_cle)\n",
    "\n",
    "df_imputed_hungarian = pd.DataFrame(imputer.transform(hung_encoded), columns=hung_encoded.columns)\n",
    "print(df_imputed_hungarian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41793a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_hungarian.to_csv('Hungarian Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2803c16",
   "metadata": {},
   "source": [
    "## Switzerland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5452ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2    3   4  5  6    7  8    9  10 11 12  13\n",
      "0    32   1   1   95   0  ?  0  127  0   .7  1  ?  ?   1\n",
      "1    34   1   4  115   0  ?  ?  154  0   .2  1  ?  ?   1\n",
      "2    35   1   4    ?   0  ?  0  130  1    ?  ?  ?  7   3\n",
      "3    36   1   4  110   0  ?  0  125  1    1  2  ?  6   1\n",
      "4    38   0   4  105   0  ?  0  166  0  2.8  1  ?  ?   2\n",
      "..   ..  ..  ..  ...  .. .. ..  ... ..  ... .. .. ..  ..\n",
      "118  70   1   4  115   0  0  1   92  1    0  2  ?  7   1\n",
      "119  70   1   4  140   0  1  0  157  1    2  2  ?  7   3\n",
      "120  72   1   3  160   0  ?  2  114  0  1.6  2  2  ?   0\n",
      "121  73   0   3  160   0  0  1  121  0    0  1  ?  3   1\n",
      "122  74   1   2  145   0  ?  1  123  0  1.3  1  ?  ?   1\n",
      "\n",
      "[123 rows x 14 columns]\n",
      "Missing values: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_20604\\3852960317.py:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_switzerland.replace('?', pd.np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "switzerland = '/Users/votri/Downloads/Pakula ML/processed.switzerland.data'\n",
    "\n",
    "df_switzerland = pd.read_csv(switzerland, header=None)\n",
    "print(df_switzerland)\n",
    "\n",
    "df_switzerland.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_switzerland.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f88ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2      3    4    5    6      7    8     9    10   11   12  \\\n",
      "0    32.0  1.0  1.0   95.0  0.0  0.2  0.0  127.0  0.0  0.70  1.0  1.0  4.6   \n",
      "1    34.0  1.0  4.0  115.0  0.0  0.2  0.4  154.0  0.0  0.20  1.0  1.0  4.6   \n",
      "2    35.0  1.0  4.0  123.6  0.0  0.2  0.0  130.0  1.0  0.88  1.6  1.0  7.0   \n",
      "3    36.0  1.0  4.0  110.0  0.0  0.2  0.0  125.0  1.0  1.00  2.0  1.0  6.0   \n",
      "4    38.0  0.0  4.0  105.0  0.0  0.2  0.0  166.0  0.0  2.80  1.0  1.0  4.6   \n",
      "..    ...  ...  ...    ...  ...  ...  ...    ...  ...   ...  ...  ...  ...   \n",
      "118  70.0  1.0  4.0  115.0  0.0  0.0  1.0   92.0  1.0  0.00  2.0  1.0  7.0   \n",
      "119  70.0  1.0  4.0  140.0  0.0  1.0  0.0  157.0  1.0  2.00  2.0  1.0  7.0   \n",
      "120  72.0  1.0  3.0  160.0  0.0  0.2  2.0  114.0  0.0  1.60  2.0  2.0  4.6   \n",
      "121  73.0  0.0  3.0  160.0  0.0  0.0  1.0  121.0  0.0  0.00  1.0  1.0  3.0   \n",
      "122  74.0  1.0  2.0  145.0  0.0  0.2  1.0  123.0  0.0  1.30  1.0  1.0  4.6   \n",
      "\n",
      "      13  \n",
      "0    1.0  \n",
      "1    1.0  \n",
      "2    3.0  \n",
      "3    1.0  \n",
      "4    2.0  \n",
      "..   ...  \n",
      "118  1.0  \n",
      "119  3.0  \n",
      "120  0.0  \n",
      "121  1.0  \n",
      "122  1.0  \n",
      "\n",
      "[123 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_imputed_swi = pd.DataFrame(imputer.transform(df_switzerland), columns=df_switzerland.columns)\n",
    "\n",
    "print(df_imputed_swi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc29fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_swi.to_csv('Switzerland Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb22fd0",
   "metadata": {},
   "source": [
    "## Long Beach, VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec62962e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2    3    4  5   6    7  8    9  10 11 12  13\n",
      "0    63   1   4  140  260  0   1  112  1    3  2  ?  ?   2\n",
      "1    44   1   4  130  209  0   1  127  0    0  ?  ?  ?   0\n",
      "2    60   1   4  132  218  0   1  140  1  1.5  3  ?  ?   2\n",
      "3    55   1   4  142  228  0   1  149  1  2.5  1  ?  ?   1\n",
      "4    66   1   3  110  213  1   2   99  1  1.3  2  ?  ?   0\n",
      "..   ..  ..  ..  ...  ... ..  ..  ... ..  ... .. .. ..  ..\n",
      "195  54   0   4  127  333  1   1  154  0    0  ?  ?  ?   1\n",
      "196  62   1   1    ?  139  0   1    ?  ?    ?  ?  ?  ?   0\n",
      "197  55   1   4  122  223  1   1  100  0    0  ?  ?  6   2\n",
      "198  58   1   4    ?  385  1   2    ?  ?    ?  ?  ?  ?   0\n",
      "199  62   1   2  120  254  0   2   93  1    0  ?  ?  ?   1\n",
      "\n",
      "[200 rows x 14 columns]\n",
      "Missing values: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_20604\\3190730457.py:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_va.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "va = '/Users/votri/Downloads/Pakula ML/processed.va.data'\n",
    "\n",
    "df_va = pd.read_csv(va, header=None)\n",
    "print(df_va)\n",
    "\n",
    "df_va.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_va.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed33c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2      3      4    5    6      7    8     9    10    11  \\\n",
      "0    63.0  1.0  4.0  140.0  260.0  0.0  1.0  112.0  1.0  3.00  2.0  0.80   \n",
      "1    44.0  1.0  4.0  130.0  209.0  0.0  1.0  127.0  0.0  0.00  1.6  1.00   \n",
      "2    60.0  1.0  4.0  132.0  218.0  0.0  1.0  140.0  1.0  1.50  3.0  1.32   \n",
      "3    55.0  1.0  4.0  142.0  228.0  0.0  1.0  149.0  1.0  2.50  1.0  0.40   \n",
      "4    66.0  1.0  3.0  110.0  213.0  1.0  2.0   99.0  1.0  1.30  2.0  0.40   \n",
      "..    ...  ...  ...    ...    ...  ...  ...    ...  ...   ...  ...   ...   \n",
      "195  54.0  0.0  4.0  127.0  333.0  1.0  1.0  154.0  0.0  0.00  1.2  0.60   \n",
      "196  62.0  1.0  1.0  123.6  139.0  0.0  1.0  142.8  0.2  0.88  1.6  1.00   \n",
      "197  55.0  1.0  4.0  122.0  223.0  1.0  1.0  100.0  0.0  0.00  1.8  0.20   \n",
      "198  58.0  1.0  4.0  140.8  385.0  1.0  2.0  155.0  0.4  1.70  1.6  1.00   \n",
      "199  62.0  1.0  2.0  120.0  254.0  0.0  2.0   93.0  1.0  0.00  2.2  1.20   \n",
      "\n",
      "       12   13  \n",
      "0    7.00  2.0  \n",
      "1    5.68  0.0  \n",
      "2    6.00  2.0  \n",
      "3    3.60  1.0  \n",
      "4    4.88  0.0  \n",
      "..    ...  ...  \n",
      "195  3.80  1.0  \n",
      "196  4.60  0.0  \n",
      "197  6.00  2.0  \n",
      "198  4.60  0.0  \n",
      "199  6.20  1.0  \n",
      "\n",
      "[200 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_imputed_va = pd.DataFrame(imputer.transform(df_va), columns=df_va.columns)\n",
    "\n",
    "print(df_imputed_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f8e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_va.to_csv('Virginia Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d86e60",
   "metadata": {},
   "source": [
    "## Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba9c89b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2      3      4    5    6      7    8     9    10   11   12  \\\n",
      "0    63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.30  3.0  0.0  6.0   \n",
      "1    67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.50  2.0  3.0  3.0   \n",
      "2    67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.60  2.0  2.0  7.0   \n",
      "3    37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.50  3.0  0.0  3.0   \n",
      "4    41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.40  1.0  0.0  3.0   \n",
      "..    ...  ...  ...    ...    ...  ...  ...    ...  ...   ...  ...  ...  ...   \n",
      "915  54.0  0.0  4.0  127.0  333.0  1.0  1.0  154.0  0.0  0.00  1.2  0.6  3.8   \n",
      "916  62.0  1.0  1.0  123.6  139.0  0.0  1.0  142.8  0.2  0.88  1.6  1.0  4.6   \n",
      "917  55.0  1.0  4.0  122.0  223.0  1.0  1.0  100.0  0.0  0.00  1.8  0.2  6.0   \n",
      "918  58.0  1.0  4.0  140.8  385.0  1.0  2.0  155.0  0.4  1.70  1.6  1.0  4.6   \n",
      "919  62.0  1.0  2.0  120.0  254.0  0.0  2.0   93.0  1.0  0.00  2.2  1.2  6.2   \n",
      "\n",
      "      13  \n",
      "0    0.0  \n",
      "1    2.0  \n",
      "2    1.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "..   ...  \n",
      "915  1.0  \n",
      "916  0.0  \n",
      "917  2.0  \n",
      "918  0.0  \n",
      "919  1.0  \n",
      "\n",
      "[920 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([df_imputed_cle, df_imputed_hungarian, df_imputed_swi, df_imputed_va], ignore_index=True)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78eaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('Combined Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe94dc",
   "metadata": {},
   "source": [
    "# Rounding data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5a60a",
   "metadata": {},
   "source": [
    "## Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64a0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "904ebc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding_data(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        #cleveland\n",
    "        x['ca'][i] = x['ca'][i].round(0)\n",
    "        x['thal'][i] = np.array([6,3,7])[np.argmin(abs(np.array([6,3,7])- x['thal'][i]))]\n",
    "        #hungarian\n",
    "        x['fbs'][i] = x['fbs'][i].round(0)\n",
    "        x['restecg'][i] = x['restecg'][i].round(0)\n",
    "        x['exang'][i] = x['exang'][i].round(0)\n",
    "        x['slope'][i] = x['slope'][i].round(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88461009",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = ['data/Cleveland Imputed Data.csv','data/Hungarian Imputed Data.csv','data/Switzerland Imputed Data.csv','data/Virginia Imputed Data.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df7671c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = columns_names\n",
    "    df_rounded = rounding_data(df)\n",
    "    df_rounded.to_csv(str(path[5:][:-17]) + '_rounded.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38706ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in path_list:\n",
    "    process_data(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
