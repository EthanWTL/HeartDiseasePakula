{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed05285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2c3ed",
   "metadata": {},
   "source": [
    "# Local data for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37651f",
   "metadata": {},
   "source": [
    "## Cleveland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e281b4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
      "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
      "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
      "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
      "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
      "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
      "\n",
      "     slope   ca thal  num  \n",
      "0      3.0  0.0  6.0    0  \n",
      "1      2.0  3.0  3.0    2  \n",
      "2      2.0  2.0  7.0    1  \n",
      "3      3.0  0.0  3.0    0  \n",
      "4      1.0  0.0  3.0    0  \n",
      "..     ...  ...  ...  ...  \n",
      "298    2.0  0.0  7.0    1  \n",
      "299    2.0  2.0  7.0    2  \n",
      "300    2.0  1.0  7.0    3  \n",
      "301    2.0  1.0  3.0    1  \n",
      "302    1.0    ?  3.0    0  \n",
      "\n",
      "[303 rows x 14 columns]\n",
      "Missing values: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_6792\\3715974877.py:11: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_cleveland.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cleveland = 'data/processed.cleveland.data'\n",
    "\n",
    "df_cleveland = pd.read_csv(cleveland, header=None)\n",
    "\n",
    "columns_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "df_cleveland.columns = columns_names\n",
    "print(df_cleveland)\n",
    "\n",
    "df_cleveland.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_cleveland.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d7a145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "3       0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "298     1.0     0.0     0.0     0.0          1.0          0.0          0.0   \n",
      "299     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "300     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "301     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "302     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...   age  sex  trestbps   chol  fbs  \\\n",
      "0          0.0        0.0        1.0  ...  63.0  1.0     145.0  233.0  1.0   \n",
      "1          0.0        1.0        0.0  ...  67.0  1.0     160.0  286.0  0.0   \n",
      "2          0.0        1.0        0.0  ...  67.0  1.0     120.0  229.0  0.0   \n",
      "3          0.0        0.0        1.0  ...  37.0  1.0     130.0  250.0  0.0   \n",
      "4          1.0        0.0        0.0  ...  41.0  0.0     130.0  204.0  0.0   \n",
      "..         ...        ...        ...  ...   ...  ...       ...    ...  ...   \n",
      "298        0.0        1.0        0.0  ...  45.0  1.0     110.0  264.0  0.0   \n",
      "299        0.0        1.0        0.0  ...  68.0  1.0     144.0  193.0  1.0   \n",
      "300        0.0        1.0        0.0  ...  57.0  1.0     130.0  131.0  0.0   \n",
      "301        0.0        1.0        0.0  ...  57.0  0.0     130.0  236.0  0.0   \n",
      "302        1.0        0.0        0.0  ...  38.0  1.0     138.0  175.0  0.0   \n",
      "\n",
      "     thalach  exang  oldpeak   ca  num  \n",
      "0      150.0    0.0      2.3  0.0    0  \n",
      "1      108.0    1.0      1.5  3.0    2  \n",
      "2      129.0    1.0      2.6  2.0    1  \n",
      "3      187.0    0.0      3.5  0.0    0  \n",
      "4      172.0    0.0      1.4  0.0    0  \n",
      "..       ...    ...      ...  ...  ...  \n",
      "298    132.0    0.0      1.2  0.0    1  \n",
      "299    141.0    0.0      3.4  2.0    2  \n",
      "300    115.0    1.0      1.2  1.0    3  \n",
      "301    174.0    0.0      0.0  1.0    1  \n",
      "302    173.0    0.0      0.0  NaN    0  \n",
      "\n",
      "[303 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Use One-hot Encoder to use Hamming distance for KNN later\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_data = encoder.fit_transform(df_cleveland[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "cle_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "cle_encoded = pd.concat([cle_encoded, df_cleveland[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "cle_encoded = cle_encoded.drop('thal_nan', axis=1)\n",
    "\n",
    "print(cle_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d5dcce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
      "0       1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
      "1       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "2       0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
      "3       0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "4       0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "..      ...     ...     ...     ...          ...          ...          ...   \n",
      "298     1.0     0.0     0.0     0.0          1.0          0.0          0.0   \n",
      "299     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "300     0.0     0.0     0.0     1.0          1.0          0.0          0.0   \n",
      "301     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
      "302     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
      "\n",
      "     slope_1.0  slope_2.0  slope_3.0  ...   age  sex  trestbps   chol  fbs  \\\n",
      "0          0.0        0.0        1.0  ...  63.0  1.0     145.0  233.0  1.0   \n",
      "1          0.0        1.0        0.0  ...  67.0  1.0     160.0  286.0  0.0   \n",
      "2          0.0        1.0        0.0  ...  67.0  1.0     120.0  229.0  0.0   \n",
      "3          0.0        0.0        1.0  ...  37.0  1.0     130.0  250.0  0.0   \n",
      "4          1.0        0.0        0.0  ...  41.0  0.0     130.0  204.0  0.0   \n",
      "..         ...        ...        ...  ...   ...  ...       ...    ...  ...   \n",
      "298        0.0        1.0        0.0  ...  45.0  1.0     110.0  264.0  0.0   \n",
      "299        0.0        1.0        0.0  ...  68.0  1.0     144.0  193.0  1.0   \n",
      "300        0.0        1.0        0.0  ...  57.0  1.0     130.0  131.0  0.0   \n",
      "301        0.0        1.0        0.0  ...  57.0  0.0     130.0  236.0  0.0   \n",
      "302        1.0        0.0        0.0  ...  38.0  1.0     138.0  175.0  0.0   \n",
      "\n",
      "     thalach  exang  oldpeak   ca  num  \n",
      "0      150.0    0.0      2.3  0.0  0.0  \n",
      "1      108.0    1.0      1.5  3.0  2.0  \n",
      "2      129.0    1.0      2.6  2.0  1.0  \n",
      "3      187.0    0.0      3.5  0.0  0.0  \n",
      "4      172.0    0.0      1.4  0.0  0.0  \n",
      "..       ...    ...      ...  ...  ...  \n",
      "298    132.0    0.0      1.2  0.0  1.0  \n",
      "299    141.0    0.0      3.4  2.0  2.0  \n",
      "300    115.0    1.0      1.2  1.0  3.0  \n",
      "301    174.0    0.0      0.0  1.0  1.0  \n",
      "302    173.0    0.0      0.0  0.0  0.0  \n",
      "\n",
      "[303 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed_cle = pd.DataFrame(imputer.fit_transform(cle_encoded))\n",
    "df_imputed_cle.columns = cle_encoded.columns[0:]\n",
    "\n",
    "print(df_imputed_cle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87fcf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_cle.to_csv('Cleveland Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8192c34",
   "metadata": {},
   "source": [
    "## Hungarian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4176901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp trestbps chol fbs restecg thalach exang  oldpeak slope ca  \\\n",
      "0     28    1   2      130  132   0       2     185     0      0.0     ?  ?   \n",
      "1     29    1   2      120  243   0       0     160     0      0.0     ?  ?   \n",
      "2     29    1   2      140    ?   0       0     170     0      0.0     ?  ?   \n",
      "3     30    0   1      170  237   0       1     170     0      0.0     ?  ?   \n",
      "4     31    0   2      100  219   0       1     150     0      0.0     ?  ?   \n",
      "..   ...  ...  ..      ...  ...  ..     ...     ...   ...      ...   ... ..   \n",
      "289   52    1   4      160  331   0       0      94     1      2.5     ?  ?   \n",
      "290   54    0   3      130  294   0       1     100     1      0.0     2  ?   \n",
      "291   56    1   4      155  342   1       0     150     1      3.0     2  ?   \n",
      "292   58    0   2      180  393   0       0     110     1      1.0     2  ?   \n",
      "293   65    1   4      130  275   0       1     115     1      1.0     2  ?   \n",
      "\n",
      "    thal  num  \n",
      "0      ?    0  \n",
      "1      ?    0  \n",
      "2      ?    0  \n",
      "3      6    0  \n",
      "4      ?    0  \n",
      "..   ...  ...  \n",
      "289    ?    1  \n",
      "290    ?    1  \n",
      "291    ?    1  \n",
      "292    7    1  \n",
      "293    ?    1  \n",
      "\n",
      "[294 rows x 14 columns]\n",
      "Missing values: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_6792\\1664317974.py:8: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_hungarian.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "hungarian = 'data/processed.hungarian.data'\n",
    "\n",
    "df_hungarian = pd.read_csv(hungarian, header=None)\n",
    "\n",
    "df_hungarian.columns = columns_names\n",
    "print(df_hungarian)\n",
    "\n",
    "df_hungarian.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_hungarian.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93d3e871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cp_1  cp_2  cp_3  cp_4  restecg_0  restecg_1  restecg_2  restecg_nan  \\\n",
      "0     0.0   1.0   0.0   0.0        0.0        0.0        1.0          0.0   \n",
      "1     0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "2     0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "3     1.0   0.0   0.0   0.0        0.0        1.0        0.0          0.0   \n",
      "4     0.0   1.0   0.0   0.0        0.0        1.0        0.0          0.0   \n",
      "..    ...   ...   ...   ...        ...        ...        ...          ...   \n",
      "289   0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "290   0.0   0.0   1.0   0.0        0.0        1.0        0.0          0.0   \n",
      "291   0.0   0.0   0.0   1.0        1.0        0.0        0.0          0.0   \n",
      "292   0.0   1.0   0.0   0.0        1.0        0.0        0.0          0.0   \n",
      "293   0.0   0.0   0.0   1.0        0.0        1.0        0.0          0.0   \n",
      "\n",
      "     slope_1  slope_2  ...  age  sex  trestbps  chol  fbs  thalach  exang  \\\n",
      "0        0.0      0.0  ...   28    1       130   132    0      185      0   \n",
      "1        0.0      0.0  ...   29    1       120   243    0      160      0   \n",
      "2        0.0      0.0  ...   29    1       140   NaN    0      170      0   \n",
      "3        0.0      0.0  ...   30    0       170   237    0      170      0   \n",
      "4        0.0      0.0  ...   31    0       100   219    0      150      0   \n",
      "..       ...      ...  ...  ...  ...       ...   ...  ...      ...    ...   \n",
      "289      0.0      0.0  ...   52    1       160   331    0       94      1   \n",
      "290      0.0      1.0  ...   54    0       130   294    0      100      1   \n",
      "291      0.0      1.0  ...   56    1       155   342    1      150      1   \n",
      "292      0.0      1.0  ...   58    0       180   393    0      110      1   \n",
      "293      0.0      1.0  ...   65    1       130   275    0      115      1   \n",
      "\n",
      "     oldpeak   ca num  \n",
      "0        0.0  NaN   0  \n",
      "1        0.0  NaN   0  \n",
      "2        0.0  NaN   0  \n",
      "3        0.0  NaN   0  \n",
      "4        0.0  NaN   0  \n",
      "..       ...  ...  ..  \n",
      "289      2.5  NaN   1  \n",
      "290      0.0  NaN   1  \n",
      "291      3.0  NaN   1  \n",
      "292      1.0  NaN   1  \n",
      "293      1.0  NaN   1  \n",
      "\n",
      "[294 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_data = encoder.fit_transform(df_hungarian[['cp', 'restecg', 'slope', 'thal']])\n",
    "\n",
    "hung_encoded = pd.DataFrame(encoded_data, columns=encoder.get_feature_names(['cp', 'restecg', 'slope', 'thal']))\n",
    "\n",
    "hung_encoded = pd.concat([hung_encoded, df_hungarian[['age','sex','trestbps','chol','fbs','thalach','exang','oldpeak','ca','num']]], axis=1)\n",
    "\n",
    "print(hung_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e79205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cp_1', 'cp_2', 'cp_3', 'cp_4', 'restecg_0', 'restecg_1', 'restecg_2',\n",
      "       'restecg_nan', 'slope_1', 'slope_2', 'slope_3', 'slope_nan', 'thal_3',\n",
      "       'thal_6', 'thal_7', 'thal_nan', 'age', 'sex', 'trestbps', 'chol', 'fbs',\n",
      "       'thalach', 'exang', 'oldpeak', 'ca', 'num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(hung_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d255b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- cp_1\n",
      "- cp_2\n",
      "- cp_3\n",
      "- cp_4\n",
      "- restecg_0\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- cp_1.0\n",
      "- cp_2.0\n",
      "- cp_3.0\n",
      "- cp_4.0\n",
      "- restecg_0.0\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 26 features, but KNNImputer is expecting 23 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m imputer \u001b[38;5;241m=\u001b[39m KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      2\u001b[0m imputer\u001b[38;5;241m.\u001b[39mfit(df_imputed_cle)\n\u001b[1;32m----> 4\u001b[0m df_imputed_hungarian \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhung_encoded\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mhung_encoded\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_imputed_hungarian)\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\impute\\_knn.py:245\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 245\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m mask \u001b[38;5;241m=\u001b[39m _get_mask(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values)\n\u001b[0;32m    255\u001b[0m mask_fit_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_fit_X\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\users\\votri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 26 features, but KNNImputer is expecting 23 features as input."
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(df_imputed_cle)\n",
    "\n",
    "df_imputed_hungarian = pd.DataFrame(imputer.transform(hung_encoded), columns=hung_encoded.columns)\n",
    "print(df_imputed_hungarian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41793a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_hungarian.to_csv('Hungarian Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2803c16",
   "metadata": {},
   "source": [
    "## Switzerland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5452ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2    3   4  5  6    7  8    9  10 11 12  13\n",
      "0    32   1   1   95   0  ?  0  127  0   .7  1  ?  ?   1\n",
      "1    34   1   4  115   0  ?  ?  154  0   .2  1  ?  ?   1\n",
      "2    35   1   4    ?   0  ?  0  130  1    ?  ?  ?  7   3\n",
      "3    36   1   4  110   0  ?  0  125  1    1  2  ?  6   1\n",
      "4    38   0   4  105   0  ?  0  166  0  2.8  1  ?  ?   2\n",
      "..   ..  ..  ..  ...  .. .. ..  ... ..  ... .. .. ..  ..\n",
      "118  70   1   4  115   0  0  1   92  1    0  2  ?  7   1\n",
      "119  70   1   4  140   0  1  0  157  1    2  2  ?  7   3\n",
      "120  72   1   3  160   0  ?  2  114  0  1.6  2  2  ?   0\n",
      "121  73   0   3  160   0  0  1  121  0    0  1  ?  3   1\n",
      "122  74   1   2  145   0  ?  1  123  0  1.3  1  ?  ?   1\n",
      "\n",
      "[123 rows x 14 columns]\n",
      "Missing values: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_20604\\3852960317.py:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_switzerland.replace('?', pd.np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "switzerland = '/Users/votri/Downloads/Pakula ML/processed.switzerland.data'\n",
    "\n",
    "df_switzerland = pd.read_csv(switzerland, header=None)\n",
    "print(df_switzerland)\n",
    "\n",
    "df_switzerland.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_switzerland.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f88ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2      3    4    5    6      7    8     9    10   11   12  \\\n",
      "0    32.0  1.0  1.0   95.0  0.0  0.2  0.0  127.0  0.0  0.70  1.0  1.0  4.6   \n",
      "1    34.0  1.0  4.0  115.0  0.0  0.2  0.4  154.0  0.0  0.20  1.0  1.0  4.6   \n",
      "2    35.0  1.0  4.0  123.6  0.0  0.2  0.0  130.0  1.0  0.88  1.6  1.0  7.0   \n",
      "3    36.0  1.0  4.0  110.0  0.0  0.2  0.0  125.0  1.0  1.00  2.0  1.0  6.0   \n",
      "4    38.0  0.0  4.0  105.0  0.0  0.2  0.0  166.0  0.0  2.80  1.0  1.0  4.6   \n",
      "..    ...  ...  ...    ...  ...  ...  ...    ...  ...   ...  ...  ...  ...   \n",
      "118  70.0  1.0  4.0  115.0  0.0  0.0  1.0   92.0  1.0  0.00  2.0  1.0  7.0   \n",
      "119  70.0  1.0  4.0  140.0  0.0  1.0  0.0  157.0  1.0  2.00  2.0  1.0  7.0   \n",
      "120  72.0  1.0  3.0  160.0  0.0  0.2  2.0  114.0  0.0  1.60  2.0  2.0  4.6   \n",
      "121  73.0  0.0  3.0  160.0  0.0  0.0  1.0  121.0  0.0  0.00  1.0  1.0  3.0   \n",
      "122  74.0  1.0  2.0  145.0  0.0  0.2  1.0  123.0  0.0  1.30  1.0  1.0  4.6   \n",
      "\n",
      "      13  \n",
      "0    1.0  \n",
      "1    1.0  \n",
      "2    3.0  \n",
      "3    1.0  \n",
      "4    2.0  \n",
      "..   ...  \n",
      "118  1.0  \n",
      "119  3.0  \n",
      "120  0.0  \n",
      "121  1.0  \n",
      "122  1.0  \n",
      "\n",
      "[123 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_imputed_swi = pd.DataFrame(imputer.transform(df_switzerland), columns=df_switzerland.columns)\n",
    "\n",
    "print(df_imputed_swi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc29fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_swi.to_csv('Switzerland Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb22fd0",
   "metadata": {},
   "source": [
    "## Long Beach, VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec62962e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2    3    4  5   6    7  8    9  10 11 12  13\n",
      "0    63   1   4  140  260  0   1  112  1    3  2  ?  ?   2\n",
      "1    44   1   4  130  209  0   1  127  0    0  ?  ?  ?   0\n",
      "2    60   1   4  132  218  0   1  140  1  1.5  3  ?  ?   2\n",
      "3    55   1   4  142  228  0   1  149  1  2.5  1  ?  ?   1\n",
      "4    66   1   3  110  213  1   2   99  1  1.3  2  ?  ?   0\n",
      "..   ..  ..  ..  ...  ... ..  ..  ... ..  ... .. .. ..  ..\n",
      "195  54   0   4  127  333  1   1  154  0    0  ?  ?  ?   1\n",
      "196  62   1   1    ?  139  0   1    ?  ?    ?  ?  ?  ?   0\n",
      "197  55   1   4  122  223  1   1  100  0    0  ?  ?  6   2\n",
      "198  58   1   4    ?  385  1   2    ?  ?    ?  ?  ?  ?   0\n",
      "199  62   1   2  120  254  0   2   93  1    0  ?  ?  ?   1\n",
      "\n",
      "[200 rows x 14 columns]\n",
      "Missing values: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\votri\\AppData\\Local\\Temp\\ipykernel_20604\\3190730457.py:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_va.replace('?', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "va = '/Users/votri/Downloads/Pakula ML/processed.va.data'\n",
    "\n",
    "df_va = pd.read_csv(va, header=None)\n",
    "print(df_va)\n",
    "\n",
    "df_va.replace('?', pd.np.nan, inplace=True)\n",
    "count_missing = df_va.isna().any(axis=1).sum()\n",
    "print('Missing values:', count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed33c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2      3      4    5    6      7    8     9    10    11  \\\n",
      "0    63.0  1.0  4.0  140.0  260.0  0.0  1.0  112.0  1.0  3.00  2.0  0.80   \n",
      "1    44.0  1.0  4.0  130.0  209.0  0.0  1.0  127.0  0.0  0.00  1.6  1.00   \n",
      "2    60.0  1.0  4.0  132.0  218.0  0.0  1.0  140.0  1.0  1.50  3.0  1.32   \n",
      "3    55.0  1.0  4.0  142.0  228.0  0.0  1.0  149.0  1.0  2.50  1.0  0.40   \n",
      "4    66.0  1.0  3.0  110.0  213.0  1.0  2.0   99.0  1.0  1.30  2.0  0.40   \n",
      "..    ...  ...  ...    ...    ...  ...  ...    ...  ...   ...  ...   ...   \n",
      "195  54.0  0.0  4.0  127.0  333.0  1.0  1.0  154.0  0.0  0.00  1.2  0.60   \n",
      "196  62.0  1.0  1.0  123.6  139.0  0.0  1.0  142.8  0.2  0.88  1.6  1.00   \n",
      "197  55.0  1.0  4.0  122.0  223.0  1.0  1.0  100.0  0.0  0.00  1.8  0.20   \n",
      "198  58.0  1.0  4.0  140.8  385.0  1.0  2.0  155.0  0.4  1.70  1.6  1.00   \n",
      "199  62.0  1.0  2.0  120.0  254.0  0.0  2.0   93.0  1.0  0.00  2.2  1.20   \n",
      "\n",
      "       12   13  \n",
      "0    7.00  2.0  \n",
      "1    5.68  0.0  \n",
      "2    6.00  2.0  \n",
      "3    3.60  1.0  \n",
      "4    4.88  0.0  \n",
      "..    ...  ...  \n",
      "195  3.80  1.0  \n",
      "196  4.60  0.0  \n",
      "197  6.00  2.0  \n",
      "198  4.60  0.0  \n",
      "199  6.20  1.0  \n",
      "\n",
      "[200 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_imputed_va = pd.DataFrame(imputer.transform(df_va), columns=df_va.columns)\n",
    "\n",
    "print(df_imputed_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f8e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_va.to_csv('Virginia Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d86e60",
   "metadata": {},
   "source": [
    "## Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba9c89b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2      3      4    5    6      7    8     9    10   11   12  \\\n",
      "0    63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.30  3.0  0.0  6.0   \n",
      "1    67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.50  2.0  3.0  3.0   \n",
      "2    67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.60  2.0  2.0  7.0   \n",
      "3    37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.50  3.0  0.0  3.0   \n",
      "4    41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.40  1.0  0.0  3.0   \n",
      "..    ...  ...  ...    ...    ...  ...  ...    ...  ...   ...  ...  ...  ...   \n",
      "915  54.0  0.0  4.0  127.0  333.0  1.0  1.0  154.0  0.0  0.00  1.2  0.6  3.8   \n",
      "916  62.0  1.0  1.0  123.6  139.0  0.0  1.0  142.8  0.2  0.88  1.6  1.0  4.6   \n",
      "917  55.0  1.0  4.0  122.0  223.0  1.0  1.0  100.0  0.0  0.00  1.8  0.2  6.0   \n",
      "918  58.0  1.0  4.0  140.8  385.0  1.0  2.0  155.0  0.4  1.70  1.6  1.0  4.6   \n",
      "919  62.0  1.0  2.0  120.0  254.0  0.0  2.0   93.0  1.0  0.00  2.2  1.2  6.2   \n",
      "\n",
      "      13  \n",
      "0    0.0  \n",
      "1    2.0  \n",
      "2    1.0  \n",
      "3    0.0  \n",
      "4    0.0  \n",
      "..   ...  \n",
      "915  1.0  \n",
      "916  0.0  \n",
      "917  2.0  \n",
      "918  0.0  \n",
      "919  1.0  \n",
      "\n",
      "[920 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([df_imputed_cle, df_imputed_hungarian, df_imputed_swi, df_imputed_va], ignore_index=True)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78eaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('Combined Imputed Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe94dc",
   "metadata": {},
   "source": [
    "# Rounding data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5a60a",
   "metadata": {},
   "source": [
    "## Cleveland"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 1,
   "id": "51a85143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
>>>>>>> 655959c4198aa3c0dc43b1c90feb5b7757ddc44c
   "id": "c64a0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "904ebc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding_data(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        #cleveland\n",
    "        x['ca'][i] = x['ca'][i].round(0)\n",
    "        x['thal'][i] = np.array([6,3,7])[np.argmin(abs(np.array([6,3,7])- x['thal'][i]))]\n",
    "        #hungarian\n",
    "        x['fbs'][i] = x['fbs'][i].round(0)\n",
    "        x['restecg'][i] = x['restecg'][i].round(0)\n",
    "        x['exang'][i] = x['exang'][i].round(0)\n",
    "        x['slope'][i] = x['slope'][i].round(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88461009",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = ['data/Cleveland Imputed Data.csv','data/Hungarian Imputed Data.csv','data/Switzerland Imputed Data.csv','data/Virginia Imputed Data.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df7671c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = columns_names\n",
    "    df_rounded = rounding_data(df)\n",
    "    df_rounded.to_csv(str(path[5:][:-17]) + '_rounded.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38706ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in path_list:\n",
    "    process_data(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf5b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9d96d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_1808\\2332859724.py:1: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df_nan = df.replace('?', pd.np.nan, inplace=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_nan \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m, pd\u001b[38;5;241m.\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf_nan\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mslope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mis_null\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df_nan = df.replace('?', pd.np.nan, inplace=True)\n",
    "df_nan['slope'].is_null.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "963b3723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age  [29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n",
      " 53 54 55 56 57 58 59 60 61 62 63 65 66]\n",
      "==============\n",
      "sex  [1 0]\n",
      "==============\n",
      "cp  [2 1 3 4]\n",
      "==============\n",
      "trestbps  ['120' '140' '170' '100' '105' '110' '125' '130' '150' '98' '112' '145'\n",
      " '190' '160' '115' '142' '180' '132' '135' '?' '108' '124' '113' '122'\n",
      " '92' '118' '106' '200' '138' '136' '128' '155']\n",
      "==============\n",
      "chol  ['243' '?' '237' '219' '198' '225' '254' '298' '161' '214' '220' '160'\n",
      " '167' '308' '264' '166' '340' '209' '260' '211' '173' '283' '194' '223'\n",
      " '315' '275' '297' '292' '182' '200' '204' '241' '339' '147' '273' '307'\n",
      " '289' '215' '281' '250' '184' '245' '291' '295' '269' '196' '268' '228'\n",
      " '358' '201' '249' '266' '186' '207' '218' '412' '224' '238' '230' '163'\n",
      " '240' '280' '257' '263' '276' '284' '195' '227' '253' '187' '202' '328'\n",
      " '168' '216' '129' '190' '188' '179' '210' '272' '180' '100' '259' '468'\n",
      " '274' '320' '221' '309' '312' '171' '208' '246' '305' '217' '365' '344'\n",
      " '394' '256' '326' '277' '270' '229' '85' '347' '251' '222' '287' '318'\n",
      " '213' '294' '193' '271' '156' '267' '282' '117' '466' '247' '226' '265'\n",
      " '206' '288' '303' '338' '248' '306' '529' '392' '231' '329' '355' '233'\n",
      " '242' '603' '255' '172' '175' '290' '341' '234' '342' '404' '518' '285'\n",
      " '279' '388' '164' '336' '491' '205' '212' '331' '393']\n",
      "==============\n",
      "fbs  ['0' '?' '1']\n",
      "==============\n",
      "restecg  ['0' '1' '2' '?']\n",
      "==============\n",
      "thalach  ['160' '170' '150' '165' '184' '155' '185' '190' '168' '180' '178' '172'\n",
      " '130' '142' '98' '158' '129' '146' '145' '120' '106' '132' '140' '138'\n",
      " '167' '188' '144' '137' '136' '152' '175' '176' '118' '154' '115' '135'\n",
      " '122' '110' '90' '116' '174' '125' '?' '148' '100' '164' '139' '127'\n",
      " '162' '112' '134' '114' '128' '126' '124' '153' '166' '103' '156' '87'\n",
      " '102' '92' '99' '121' '91' '108' '96' '82' '105' '143' '119' '94']\n",
      "==============\n",
      "exang  ['0' '1' '?']\n",
      "==============\n",
      "oldpeak  [0.  1.  2.  1.5 0.5 3.  0.8 2.5 4.  5. ]\n",
      "==============\n",
      "slope  ['?' '2' '1' '3']\n",
      "==============\n",
      "ca  ['?' '0']\n",
      "==============\n",
      "thal  ['?' '6' '3' '7']\n",
      "==============\n",
      "num  [0 1]\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed.hungarian.data')\n",
    "df.columns = columns_names\n",
    "for i in columns_names:\n",
    "    print(str(i) +  \"  \" + str(df[i].unique()))\n",
    "    print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e9ee47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age  [34 35 36 38 40 41 42 43 45 46 47 48 50 51 52 53 54 55 56 57 58 59 60 61\n",
      " 62 63 64 65 66 67 68 69 70 72 73 74]\n",
      "==============\n",
      "sex  [1 0]\n",
      "==============\n",
      "cp  [4 3 2 1]\n",
      "==============\n",
      "trestbps  ['115' '?' '110' '105' '100' '135' '150' '95' '125' '145' '140' '155'\n",
      " '160' '120' '130' '165' '80' '180' '170' '200' '185']\n",
      "==============\n",
      "chol  [0]\n",
      "==============\n",
      "fbs  ['?' '0' '1']\n",
      "==============\n",
      "restecg  ['?' '0' '1' '2']\n",
      "==============\n",
      "thalach  ['154' '130' '125' '166' '156' '179' '128' '150' '120' '144' '176' '99'\n",
      " '122' '145' '140' '138' '133' '113' '118' '149' '124' '110' '139' '127'\n",
      " '92' '104' '170' '163' '60' '126' '82' '95' '115' '135' '141' '155' '83'\n",
      " '97' '98' '100' '148' '103' '121' '131' '182' '105' '175' '94' '119'\n",
      " '143' '63' '70' '77' '117' '123' '134' '72' '78' '109' '86' '114' '93'\n",
      " '67' '90' '108' '136' '?' '157']\n",
      "==============\n",
      "exang  ['0' '1' '?']\n",
      "==============\n",
      "oldpeak  ['.2' '?' '1' '2.8' '0' '-1.1' '1.6' '-1.5' '1.5' '2' '.5' '-.1' '-2.6'\n",
      " '2.1' '.7' '-.7' '2.2' '3' '.1' '.3' '-2' '-1' '1.8' '1.4' '2.6' '.9'\n",
      " '2.4' '1.1' '.4' '2.5' '1.7' '-.8' '-.5' '-.9' '3.7' '1.3']\n",
      "==============\n",
      "slope  ['1' '?' '2' '3']\n",
      "==============\n",
      "ca  ['?' '1' '2']\n",
      "==============\n",
      "thal  ['?' '7' '6' '3']\n",
      "==============\n",
      "num  [1 3 2 0 4]\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed.switzerland.data')\n",
    "df.columns = columns_names\n",
    "for i in columns_names:\n",
    "    print(str(i) +  \"  \" + str(df[i].unique()))\n",
    "    print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fb8cdbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age  [44 60 55 66 65 56 59 62 63 57 46 58 64 74 52 69 51 54 77 61 40 41 42 53\n",
      " 68 67 72 75 49 35 43 48 50 45 76 70 71 38 37]\n",
      "==============\n",
      "sex  [1 0]\n",
      "==============\n",
      "cp  [4 3 2 1]\n",
      "==============\n",
      "trestbps  ['130' '132' '142' '110' '120' '150' '180' '160' '126' '140' '?' '128'\n",
      " '170' '152' '116' '124' '0' '122' '144' '154' '125' '104' '136' '134'\n",
      " '138' '178' '146' '135' '158' '106' '112' '102' '96' '172' '155' '156'\n",
      " '118' '100' '190' '114' '127']\n",
      "==============\n",
      "chol  ['209' '218' '228' '213' '0' '236' '267' '166' '220' '177' '186' '100'\n",
      " '171' '230' '281' '203' '277' '233' '240' '153' '224' '316' '311' '270'\n",
      " '217' '214' '252' '339' '216' '276' '458' '241' '384' '297' '248' '308'\n",
      " '208' '227' '210' '245' '225' '198' '195' '161' '258' '235' '305' '223'\n",
      " '282' '349' '?' '160' '312' '283' '142' '211' '306' '222' '202' '197'\n",
      " '204' '274' '192' '298' '272' '200' '261' '181' '260' '221' '175' '219'\n",
      " '310' '232' '273' '182' '292' '289' '193' '170' '369' '173' '271' '244'\n",
      " '285' '243' '237' '165' '287' '256' '264' '226' '207' '284' '337' '254'\n",
      " '300' '333' '139' '385']\n",
      "==============\n",
      "fbs  ['0' '1' '?']\n",
      "==============\n",
      "restecg  [1 2 0]\n",
      "==============\n",
      "thalach  ['127' '140' '149' '99' '120' '105' '141' '157' '117' '?' '148' '86' '84'\n",
      " '125' '118' '124' '106' '111' '180' '129' '110' '155' '122' '133' '131'\n",
      " '80' '165' '107' '128' '160' '97' '161' '130' '108' '123' '144' '102'\n",
      " '145' '69' '138' '112' '150' '88' '132' '121' '135' '100' '162' '73'\n",
      " '154' '115' '119' '159' '94' '113' '98' '96' '151' '126' '93']\n",
      "==============\n",
      "exang  ['0' '1' '?']\n",
      "==============\n",
      "oldpeak  ['0' '1.5' '2.5' '1.3' '-0.5' '2' '0.5' '1' '?' '3' '1.6' '4' '3.5' '0.8'\n",
      " '1.7']\n",
      "==============\n",
      "slope  ['?' '3' '1' '2']\n",
      "==============\n",
      "ca  ['?' '0']\n",
      "==============\n",
      "thal  ['?' '3' '7' '6']\n",
      "==============\n",
      "num  [0 2 1 3 4]\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed.va.data')\n",
    "df.columns = columns_names\n",
    "for i in columns_names:\n",
    "    print(str(i) +  \"  \" + str(df[i].unique()))\n",
    "    print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8aee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age  [32. 34. 35. 36. 38. 40. 41. 42. 43. 45. 46. 47. 48. 50. 51. 52. 53. 54.\n",
      " 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 72. 73.\n",
      " 74.]\n",
      "==============\n",
      "sex  [1. 0.]\n",
      "==============\n",
      "cp  [1. 4. 3. 2.]\n",
      "==============\n",
      "trestbps  [ 95.  115.  123.6 110.  105.  100.  135.  150.  125.  145.  140.  155.\n",
      " 160.  120.  130.  165.   80.  180.  170.  200.  185. ]\n",
      "==============\n",
      "chol  [0.]\n",
      "==============\n",
      "fbs  [0.2 0.  1.  0.4]\n",
      "==============\n",
      "restecg  [0.  0.4 1.  2. ]\n",
      "==============\n",
      "thalach  [127.  154.  130.  125.  166.  156.  179.  128.  150.  120.  144.  176.\n",
      "  99.  122.  145.  140.  138.  133.  113.  118.  149.  124.  110.  139.\n",
      "  92.  104.  170.  163.   60.  126.   82.   95.  115.  135.  141.  155.\n",
      "  83.   97.   98.  100.  148.  103.  121.  131.  182.  105.  175.   94.\n",
      " 119.  143.   63.   70.   77.  117.  123.  134.   72.   78.  109.   86.\n",
      " 114.   93.   67.   90.  108.  136.  142.8 157. ]\n",
      "==============\n",
      "exang  [0.  1.  0.2]\n",
      "==============\n",
      "oldpeak  [ 0.7   0.2   0.88  1.    2.8   0.   -1.1   1.6  -1.5   1.5   2.    0.5\n",
      " -0.1  -2.6   2.1  -0.7   2.2   3.    0.1   0.3  -2.   -1.    1.8   1.4\n",
      "  2.6   0.9   2.4   1.1   0.4   2.5   1.7  -0.8  -0.5  -0.9   3.7   1.3\n",
      "  1.48]\n",
      "==============\n",
      "slope  [1.  1.6 2.  3.  1.8]\n",
      "==============\n",
      "ca  [1.  1.6 1.2 0.4 2.  1.4]\n",
      "==============\n",
      "thal  [4.6 7.  6.  3. ]\n",
      "==============\n",
      "num  [1. 3. 2. 0. 4.]\n",
      "==============\n"
     ]
    }
   ],
   "source": [
    "for i in columns_names:\n",
    "    print(str(i) +  \"  \" + str(df[i].unique()))\n",
    "    print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f58b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
